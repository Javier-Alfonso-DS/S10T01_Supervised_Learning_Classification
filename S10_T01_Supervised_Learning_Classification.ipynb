{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATEMENT\n",
    "We are going to practice and become familiar with classification algorithms.\n",
    "\n",
    "Level 1\n",
    "\n",
    "- Exercise 1\n",
    "Create at least three different classification models to try to predict as well as possible the delay of the flights (ArrDelay) of DelayedFlights.csv. Consider whether the flight has arrived late or not (ArrDelay > 0).\n",
    "\n",
    "- Exercise 2\n",
    "Compare the classification models using accuracy, a confidence matrix and other more advanced metrics.\n",
    "\n",
    "- Exercise 3\n",
    "Train them using the different parameters they admit.\n",
    "\n",
    "- Exercise 4\n",
    "Compare their performance using the trait/test or cross-validation approach.\n",
    "\n",
    "Level 2\n",
    "- Task 5\n",
    "Carry out some process of variable engineering to improve your prediction.\n",
    "\n",
    "Level 3\n",
    "- Exercise 6\n",
    "Do not use the variable DepDelay when making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1\n",
    "## - Exercise 1\n",
    "Create at least three different classification models to try to predict as well as possible the delay of the flights (ArrDelay) of DelayedFlights.csv. Consider whether the flight has arrived late or not (ArrDelay > 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.- Decision Tree Classification\n",
    "\n",
    "A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value.  It partitions the tree in a recursive manner called recursive partitioning. This flowchart-like structure helps you in decision making. It can be visualized like a flowchart diagram which easily mimics human level thinking. That is why decision trees are easy to understand and interpret.\n",
    "\n",
    "![](2022-03-15-11-32-53.png)\n",
    "\n",
    "Decision Tree is a white box type of ML algorithm. It shares internal decision-making logic, which is not available in the black box type of algorithms such as Neural Network. Its training time is faster compared to the neural network algorithm. The time complexity of decision trees is a function of the number of records and number of attributes in the given data. The decision tree is a distribution-free or non-parametric method, which does not depend upon probability distribution assumptions. Decision trees can handle high dimensional data with good accuracy.  \n",
    "\n",
    "From: https://app.datacamp.com/workspace/w/0ede46e9-76cd-4232-9215-adb63ba6efad/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "import Pers_lib as Pers # Import Personal functions ( my functions :) )\n",
    "\n",
    "# settings to display all columns (default is 20, now is None (all))\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('..\\Data\\DelayedFlights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset information: ✈\n",
    "![](2022-02-28-17-46-54.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jalor\\Documents\\Python Scripts\\S10_T01_Supervised_Learning_Classification\\S10_T01_Supervised_Learning_Classification.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jalor/Documents/Python%20Scripts/S10_T01_Supervised_Learning_Classification/S10_T01_Supervised_Learning_Classification.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39m# Description of raw dataframe\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jalor/Documents/Python%20Scripts/S10_T01_Supervised_Learning_Classification/S10_T01_Supervised_Learning_Classification.ipynb#ch0000013?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39;49mdescribe\u001b[39m.\u001b[39;49mT\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "# Description of raw dataframe\n",
    "df.describe.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing. \n",
    "\n",
    "Processes performed in previous task:\n",
    "\n",
    "* Delete \"non relevant\" columns: \n",
    "    *    'Unnamed: 0'➡️ repeated index\n",
    "    *    ['FlightNum','TailNum']➡️ this info is already in Distance column.\n",
    "    *    ['Origin','Dest'] ➡️ this info is already in Distance column.\n",
    "    *    ['CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay'] ➡️ the kind of delay isn't relevant, and for sure the sum is dependant.\n",
    "    *    ['Cancelled','CancellationCode','Diverted'] ➡️ no information when NaN deleted\n",
    "    *    'DepDelay' ➡️ very dependent variable with ArrDelay\n",
    "* NaN cleaning   \n",
    "* delete duplicates\n",
    "* create colum Date of Flight  \n",
    "* sample data (1% stratified by airline)    \n",
    "* standardize all numerical columns (except for day of week)\n",
    "* OHE of Unique Carrier attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns that we find not relevant for our model.\n",
    "try:\n",
    "    # Let's clean first column that is repeated index.\n",
    "    df = df.drop(columns ='Unnamed: 0')\n",
    "    # Let's delete FlightNum and TailNum as these columns doesn't give us any useful information.\n",
    "    df = df.drop(columns=['FlightNum','TailNum'])\n",
    "    # Let's delete Origin and Dest as this info is already in Distance column.\n",
    "    df = df.drop(columns=['Origin','Dest'])\n",
    "    # Finally, let's drop the columns of Delays that are not ArrDelay, because ArrDelay is the sum of all others, and we don't think that \n",
    "    # the information of what kind of delay is, will be relevant, what is sure is that they are going to be completely dependent \n",
    "    # (the sum of them are equal to ArrDelay).\n",
    "    df = df.drop(columns=['CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay'])\n",
    "    # If we delete the NaN's, the Cancellation and Diverted Columns have been deleted.\n",
    "    # That means that when whe have deleted NaN's registers, we have deleted the information of cancelled or diverted flights.  \n",
    "    # As they were so few, is ok to delete them. But also they could be useful for another exploration. \n",
    "    # In other dataset / practice we could only extract the cancelled / diverted flights to arrive to interesting conclusions. \n",
    "    df = df.drop(columns=['Cancelled','CancellationCode','Diverted'])\n",
    "    # Let's also delete the DepDelay column, as it's a very dependent variable with ArrDelay, \n",
    "    # and we want to find different relationships with the other variables.\n",
    "    df = df.drop(columns='DepDelay')\n",
    "except:\n",
    "    print(\"Columns already deleted\")\n",
    "display(df.head())\n",
    "\n",
    "# Drop all NaNs (as explained in S0901, the % of NaNs is very little in all the columns (0.4% max).   )\n",
    "list_cols = df.columns\n",
    "array_cols = list_cols.values\n",
    "NumTotalRegisters = df.shape[0]\n",
    "df = df.dropna(subset=array_cols)\n",
    "display(print(f\"Number of registers deleted are {NumTotalRegisters-df.shape[0]}\"))\n",
    "display(print(f\"% of registers with NaNs deleted are {((NumTotalRegisters-df.shape[0])/NumTotalRegisters)*100:.2f}%\"))\n",
    "\n",
    "# Delete duplicates\n",
    "index_dupl_df = df.duplicated()\n",
    "display(print(\"Num. duplicates =\", index_dupl_df.sum()))\n",
    "# As there are very few duplicates, we took them off.\n",
    "df.drop_duplicates(inplace= True)\n",
    "\n",
    "# Create column Date of the flight and delete the columns Year / Month / Day of Month. We keep DayOfWeek for potential correlations.\n",
    "## Date of the flight\n",
    "try:\n",
    "    df['Date'] = pd.to_datetime(df.Year.astype(str)+'-'+ df.Month.astype(str)+'-'+ df.DayofMonth.astype(str))\n",
    "    df = df.drop(columns=['Year','Month','DayofMonth'])\n",
    "except:\n",
    "    display(print(\"Date column already created and columns Year, Month & DayofMonth already deleted\"))\n",
    "\n",
    "# Replace number day of week to string for later graphic use\n",
    "df = df.DayOfWeek.replace({\"1\":\"MON\",\"2\":\"TUE\",\"3\":\"WED\",\"4\":\"THU\",\"5\":\"FRI\",\"6\":\"SAT\",\"7\":\"SUN\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## - Exercise 2\n",
    "Compare the classification models using accuracy, a confidence matrix and other more advanced metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## - Exercise 3\n",
    "Train them using the different parameters they admit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## - Exercise 4\n",
    "Compare their performance using the trait/test or cross-validation approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Level 2\n",
    "## - Task 5\n",
    "Carry out some process of variable engineering to improve your prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Level 3\n",
    "## - Exercise 6\n",
    "Do not use the variable DepDelay when making predictions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "494e690407c5c7c9b2fbc0a1227ada2e3d821eefed538763ba3356ad470e06f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
